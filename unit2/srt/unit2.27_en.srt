1
00:00:00,000 --> 00:00:08,000
To explain how this works, I have to talk about high dimesional Gaussians.

2
00:00:08,000 --> 00:00:13,000
These are often called multivariate Gaussians.

3
00:00:13,000 --> 00:00:20,000
The mean is now a vector with 1 element for each of the dimensions.

4
00:00:20,000 --> 00:00:23,000
The variance squared is replaced by what's called a co-variance,

5
00:00:23,000 --> 00:00:27,000
and it's a matrix with D rows and D columns,

6
00:00:27,000 --> 00:00:30,000
if the dimensionality of the estimate is D.

7
00:00:30,000 --> 00:00:36,000
And the formula is something you have to get used to.

8
00:00:36,000 --> 00:00:41,000
I'm writing it out for you, but you never get to see this again.

9
00:00:41,000 --> 00:00:44,000
To tell you the truth, even I have to look up the formula for this class,

10
00:00:44,000 --> 00:00:48,000
so I don't have it in my head, and please, don't get confused.

11
00:00:48,000 --> 00:00:52,000
Let me explain it to you more intuitively.

12
00:00:52,000 --> 00:00:55,000
Here's a 2-dimensional space.

13
00:00:55,000 --> 00:01:00,000
A 2-dimensional Gaussian is defined over that space,

14
00:01:00,000 --> 00:01:05,000
and it's possible to draw the contour lines of the Gaussian. It might look like this.

15
00:01:05,000 --> 00:01:10,000
The mean of this Gaussian is this x0, y0 pair,

16
00:01:10,000 --> 00:01:14,000
and the co-variance now defines the spread of the Gaussian

17
00:01:14,000 --> 00:01:17,000
as indicated by these contour lines.

18
00:01:17,000 --> 00:01:21,000
A Gaussian with small amounts of uncertainty might look like this.

19
00:01:21,000 --> 00:01:25,000
It might be possible to have a fairly small uncertainty in 1 dimension,

20
00:01:25,000 --> 00:01:28,000
but a huge uncertainty in the other.

21
00:01:28,000 --> 00:01:32,000
Huge uncertainty in the x-dimension is small, and the y- dimension is large.

22
00:01:32,000 --> 00:01:36,000
And when the Gaussian is tilted as shown over here,

23
00:01:36,000 --> 00:01:41,000
then the uncertainty of x and y is correlated, which means if I get information about x,

24
00:01:41,000 --> 00:01:46,000
that it actually sits over here, that would make me believe that y probably sits

25
00:01:46,000 --> 00:01:50,000
somewhere over here. That's called correlation.

26
00:01:50,000 --> 00:01:57,000
I can explain to you the entire effect of estimating velocity and using it in filtering

27
00:01:57,000 --> 00:01:59,000
using Gaussians like these,

28
00:01:59,000 --> 00:02:01,000
and it becomes really simple.

29
00:02:01,000 --> 00:02:05,000
The problem I'm going to choose is a 1-dimensional motion example.

30
00:02:05,000 --> 00:02:09,000
Let's assume at t = 1, we see our object over here.

31
00:02:09,000 --> 00:02:11,000
A t = 2 right over here.

32
00:02:11,000 --> 00:02:14,000
A t = 3 over here.

33
00:02:14,000 --> 00:02:20,000
Then you would assume that at t = 4, the object sits over here,

34
00:02:20,000 --> 00:02:24,000
and the reason why you would assume this is, even though we've just seen these different

35
00:02:24,000 --> 00:02:29,000
discrete locations, you can infer from it there is actually velocity that drives the object

36
00:02:29,000 --> 00:02:32,000
to the right side to the point over here.

37
00:02:32,000 --> 00:02:35,000
Now how does the Kalman filter address this?

38
00:02:35,000 --> 00:02:37,000
This is the true beauty of the Kalman filter.

