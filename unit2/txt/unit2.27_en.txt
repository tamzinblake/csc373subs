To explain how this works, I have to talk about high dimesional Gaussians. These are often called multivariate Gaussians.

The mean is now a vector with 1 element for each of the dimensions. The variance squared is replaced by what's called a co-variance, and it's a matrix with D rows and D columns, if the dimensionality of the estimate is D.

And the formula is something you have to get used to. I'm writing it out for you, but you never get to see this again. To tell you the truth, even I have to look up the formula for this class, so I don't have it in my head, and please, don't get confused.

Let me explain it to you more intuitively. Here's a 2-dimensional space. A 2-dimensional Gaussian is defined over that space, and it's possible to draw the contour lines of the Gaussian. It might look like this. The mean of this Gaussian is this x0, y0 pair, and the co-variance now defines the spread of the Gaussian as indicated by these contour lines.

A Gaussian with small amounts of uncertainty might look like this. It might be possible to have a fairly small uncertainty in 1 dimension, but a huge uncertainty in the other. Huge uncertainty in the x-dimension is small, and the y- dimension is large. And when the Gaussian is tilted as shown over here, then the uncertainty of x and y is correlated, which means if I get information about x, that it actually sits over here, that would make me believe that y probably sits somewhere over here. That's called correlation.

I can explain to you the entire effect of estimating velocity and using it in filtering using Gaussians like these, and it becomes really simple. The problem I'm going to choose is a 1-dimensional motion example.

Let's assume at t = 1, we see our object over here. A t = 2 right over here. A t = 3 over here. Then you would assume that at t = 4, the object sits over here, and the reason why you would assume this is, even though we've just seen these different discrete locations, you can infer from it there is actually velocity that drives the object to the right side to the point over here.

Now how does the Kalman filter address this?

This is the true beauty of the Kalman filter.
